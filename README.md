# TextFooler é¡¹ç›®ä½¿ç”¨è¯´æ˜

æœ¬é¡¹ç›®åŸºäº TextFooler å¯¹æŠ—æ”»å‡»ç®—æ³•ï¼Œç”¨äºå¯¹æ–‡æœ¬åˆ†ç±»æ¨¡å‹ï¼ˆå¦‚ BERTã€LSTMã€CNN ç­‰ï¼‰è¿›è¡Œå¯¹æŠ—æ ·æœ¬ç”Ÿæˆä¸æ”»å‡»å®éªŒã€‚ä»¥ä¸‹å†…å®¹è®°å½•äº†å®éªŒç¯å¢ƒé…ç½®ã€è¿è¡Œæ­¥éª¤ä»¥åŠå¸¸è§é—®é¢˜å¤„ç†ã€‚

---

## ğŸ“¦ 1. å®‰è£…ä¾èµ–

è¿›å…¥é¡¹ç›®æ ¹ç›®å½•ï¼š

```bash
cd TextFooler-2025
pip install -r requirements.txt
```

### âš ï¸ ä¾èµ–ç‰ˆæœ¬è¯´æ˜

åŸé¡¹ç›®ä¾èµ–å­˜åœ¨ç‰ˆæœ¬å†²çªï¼Œå¦‚ TensorFlow å’Œ Pattern ç­‰åº“æ— æ³•æ­£ç¡®å®‰è£…ã€‚ä¸‹é¢æ˜¯ä¿®æ”¹åçš„å¯è¿è¡Œç‰ˆæœ¬ä¾èµ–ï¼ˆéƒ¨åˆ†åŒ…åšäº†æ›´æ–°ï¼Œé€‚é… Python 3.10ï¼‰ï¼š

```bash
absl-py==2.1.0
astor==0.8.1
beautifulsoup4==4.9.1
boto3==1.14.7
botocore==1.17.7
certifi==2020.4.5.2
chardet==3.0.4
click==7.1.2
docutils==0.15.2
feedparser==6.0.10
gast==0.4.0
grpcio==1.51.1  
h5py==3.8.0
idna==2.9
importlib-metadata==1.6.1
jmespath==0.10.0
joblib==0.15.1
Keras-Applications==1.0.8
Keras-Preprocessing==1.1.2
lxml==4.9.2
Markdown==3.3.7
nltk==3.5
numpy==1.23.5
protobuf==3.19.6
python-dateutil==2.8.1
python-docx==0.8.10
regex==2020.6.8
requests==2.24.0
s3transfer==0.3.3
six==1.15.0
soupsieve==2.0.1
tensorboard==2.10.1
tensorflow-gpu==2.10.1
tensorflow-hub==0.12.0
termcolor==2.1.1
torch==1.13.1
tqdm==4.46.1
urllib3==1.25.9
Werkzeug==2.2.3
zipp==3.1.0
python==3.10
transformers==4.33.3
```

è¯¦è§ `requirements.txt`ã€‚

---

## ğŸ”§ 2. å®‰è£… ESIM åŒ…ï¼ˆç”¨äº NLI ä»»åŠ¡ï¼‰

```bash
cd ESIM
python setup.py install
cd ..
```

---

## ğŸ“‚ 3. å‡†å¤‡æ•°æ®å’Œé¢„è®­ç»ƒèµ„æº

- æ”»å‡»ä½¿ç”¨çš„æ•°æ®å¯ä»¥ç›´æ¥æ”¾ç½®åˆ° `data/` ç›®å½•ä¸‹
-   è‹¥æ‰“ç®—è®­ç»ƒç›®æ ‡æ¨¡å‹ï¼š
ä¸‹è½½ä½œè€…æä¾›çš„å®Œæ•´ä¸”å¤„ç†å¥½çš„[æ•°æ®é›†](https://drive.google.com/open?id=1N-FYUa5XN8qDs4SgttQQnrkeTXXAXjTv)ï¼ˆæ”¾åœ¨./TextFooler-master/traindata/xxï¼‰ï¼Œä¿®æ”¹./TextFooler-master/BERT/run_classifier_XX.pyä¸­çš„data_dirï¼Œè¿›å…¥ç›®å½•./TextFooler-master/BERTå¹¶ä¸”è¿è¡ŒæŒ‡ä»¤ï¼š
```bash
python run_classifier_XX.py
```

ä»¥ AG æ–°é—»åˆ†ç±»ä¸ºä¾‹ï¼š

```bash
cd TextFooler/BERT
python run_classifier_AG.py
```

è®­ç»ƒå®Œæˆä¼šåœ¨ `BERT/results/ag/` ä¸‹ç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

```
bert_config.json
eval_results.txt
pytorch_model.bin
vocab.txt
```

---

## ğŸ” 4. é¢„è®¡ç®—è¯å‘é‡ç›¸ä¼¼åº¦çŸ©é˜µï¼ˆå¯é€‰ï¼‰

è‹¥ä½¿ç”¨ `counter-fitted-vectors.txt`ï¼Œå¯æå‰è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µï¼ŒèŠ‚çœæ”»å‡»è®¡ç®—æ—¶é—´ï¼š

```bash
python comp_cos_sim_mat.py ./Embeddings/counter-fitted-vectors.txt
```

ç”Ÿæˆæ–‡ä»¶ï¼š`cos_sim_counter_fitting.npy`

---

## ğŸ’¥ 5. è¿è¡Œæ”»å‡»è„šæœ¬

### å¸¸ç”¨å‚æ•°è¯´æ˜

| å‚æ•° | å«ä¹‰ |
|------|------|
| `--dataset_path` | æ•°æ®é›†è·¯å¾„ |
| `--target_model` | ç›®æ ‡æ¨¡å‹ï¼Œå¦‚ `bert`ã€`lstm` |
| `--target_model_path` | æ¨¡å‹æƒé‡è·¯å¾„ï¼Œå¯ä»¥ä¸‹è½½ä½œè€…[è®­ç»ƒè¿‡çš„BERTæ¨¡å‹å‚æ•°](https://drive.google.com/drive/folders/1wKjelHFcqsT3GgA7LzWmoaAHcUkP4c7B?usp=sharing)ï¼Œ[è®­ç»ƒè¿‡çš„LSTMæ¨¡å‹å‚æ•°](https://drive.google.com/drive/folders/108myH_HHtBJX8MvhBQuvTGb-kGOce5M2?usp=sharing)ï¼Œ[è®­ç»ƒè¿‡çš„CNNæ¨¡å‹å‚æ•°](https://drive.google.com/drive/folders/1Ifowzfers0m1Aw2vE8O7SMifHUhkTEjh?usp=sharing) |
| `--counter_fitting_embeddings_path` | åæ‹Ÿåˆè¯å‘é‡è·¯å¾„ |
| `--counter_fitting_cos_sim_path` | é¢„è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µè·¯å¾„ï¼ˆå¯é€‰ï¼‰ |
| `--USE_cache_path` | USE æ¨¡å‹ç¼“å­˜è·¯å¾„ï¼ˆä¸ºç©ºåˆ™è‡ªåŠ¨ä¸‹è½½ï¼‰ |

### ç¤ºä¾‹ï¼šæ”»å‡» BERT æ¨¡å‹

```bash
python attack_classification.py \
  --dataset_path "./data" \
  --target_model bert \
  --target_model_path "./BERT/results/ag" \
  --counter_fitting_embeddings_path "./Embeddings/counter-fitted-vectors.txt" \
  --counter_fitting_cos_sim_path "./Embeddings/cos_sim_counter_fitting.npy" \
  --USE_cache_path "./USE_cache_path"
```


## ğŸ“ é¡¹ç›®ç»“æ„

```
TextFooler/
â”‚
â”œâ”€â”€ attack_classification.py        # å•å¥åˆ†ç±»æ”»å‡»ä¸»è„šæœ¬
â”œâ”€â”€ attack_nli.py                   # NLIï¼ˆå¥å¯¹ï¼‰æ”»å‡»ä¸»è„šæœ¬
â”œâ”€â”€ train_classifier.py             # è®­ç»ƒå•å¥åˆ†ç±»å™¨ï¼ˆLSTM/CNNï¼‰
â”œâ”€â”€ run_attack_classification.py    # å¯åŠ¨/ç¤ºä¾‹è„šæœ¬ï¼ˆåˆ†ç±»æ”»å‡»ï¼‰
â”œâ”€â”€ run_attack_nli.py               # å¯åŠ¨/ç¤ºä¾‹è„šæœ¬ï¼ˆNLIæ”»å‡»ï¼‰
â”œâ”€â”€ comp_cos_sim_mat.py             # ç”Ÿæˆ counter-fitted ç›¸ä¼¼åº¦çŸ©é˜µï¼ˆæˆ–ä¿®æ”¹ä¸º Top-Kï¼‰
â”œâ”€â”€ dataloader.py                   # æ•°æ®åŠ è½½ / pad / batch åŒ–
â”œâ”€â”€ modules.py                      # æ¨¡å‹æ¨¡å—ï¼ˆEmbeddingã€CNNã€LSTM ç­‰ï¼‰
â”œâ”€â”€ criteria.py                     # è¯­ä¹‰/POS/æ—¶æ€çº¦æŸå·¥å…·
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .DS_Store
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ data/                           # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ ag                         # AG æ–°é—»åˆ†ç±»æ•°æ®é›†
â”‚   â”œâ”€â”€ fake                      # fake news / fake reviews æ•°æ®é›†
â”‚   â”œâ”€â”€ imdb                       # IMDB å½±è¯„ï¼ˆæƒ…æ„Ÿåˆ†ç±»ï¼‰æ•°æ®é›†
â”‚   â”œâ”€â”€ mnli                       # MNLI åŸå§‹/é€šç”¨é›†ï¼ˆå¥å¯¹ï¼‰ï¼Œå¸¸ç”¨äº NLI
â”‚   â”œâ”€â”€ mnli_matched              # MNLI matched éªŒè¯é›†
â”‚   â””â”€â”€ mnli_mismatched            # MNLI mismatched éªŒè¯é›†
â”‚   â””â”€â”€â€¦
â”‚
â”œâ”€â”€ traindata/                        # ç”¨äºè®­ç»ƒçš„æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ ag                         # AG æ–°é—»åˆ†ç±» æ•°æ®é›†
â”‚   â”‚   â”œâ”€â”€ test.csv
â”‚   â”‚   â”œâ”€â”€ test_tok.csv
â”‚   â”‚   â”œâ”€â”€ train.csv
â”‚   â”‚   â”œâ”€â”€ train_tok.csv
â”‚   â”‚   â”œâ”€â”€ proc.py
â”‚   â”‚   â””â”€â”€â€¦
â”‚   â””â”€â”€â€¦
â”‚
â”œâ”€â”€ Embedding/                      # å‘é‡ç›®å½•ï¼ˆé¢„è®­ç»ƒè¯å‘é‡ç­‰ï¼‰
â”‚   â”œâ”€â”€ glove.6B.300d.txt                  # GloVe é¢„è®­ç»ƒè¯å‘é‡
â”‚   â”œâ”€â”€ counter-fitted-vectors.txt       # Counter-fitted åŒä¹‰è¯è¯å‘é‡
â”‚   â””â”€â”€ cos_sim_counter_fitting.npy  # é¢„è®¡ç®—çš„è¯å‘é‡ç›¸ä¼¼åº¦çŸ©é˜µ
â”‚ 
â”œâ”€â”€ BERT/                               # BERT æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py                     # åŒ…å£°æ˜
â”‚   â”œâ”€â”€ extract_features.py             # æå– BERT è¡¨å¾ç‰¹å¾
â”‚   â”œâ”€â”€ file_utils.py                   # æ¨¡å‹/ç¼“å­˜è·¯å¾„ç®¡ç†
â”‚   â”œâ”€â”€ modeling.py                     # Transformer æ¨¡å‹ä¸åˆ†ç±»å™¨ç»“æ„
â”‚   â”œâ”€â”€ optimization.py                 # ä¼˜åŒ–å™¨ & warmup ç­–ç•¥
â”‚   â”œâ”€â”€ tokenization.py                 # åˆ†è¯å™¨ & WordPiece å®ç°
â”‚   â”œâ”€â”€ run_classifier.py               # é€šç”¨ Fine-tuning è„šæœ¬
â”‚   â”œâ”€â”€ run_classifier_AG.py            # AG æ–°é—»åˆ†ç±»å¾®è°ƒ
â”‚   â”œâ”€â”€ run_classifier_Fake.py          # å‡æ–°é—»æ£€æµ‹å¾®è°ƒ
â”‚   â”œâ”€â”€ run_classifier_IMDB.py          # IMDB æƒ…æ„Ÿåˆ†ç±»å¾®è°ƒ
â”‚   â”œâ”€â”€ run_classifier_mnli.py          # MNLI è‡ªç„¶è¯­è¨€æ¨ç†ä»»åŠ¡å¾®è°ƒ
â”‚   â”œâ”€â”€ run_classifier_MR.py            # MRï¼ˆMovie Reviewï¼‰åˆ†ç±»ä»»åŠ¡
â”‚   â”œâ”€â”€ run_classifier_snli.py          # SNLI æ¨ç†ä»»åŠ¡å¾®è°ƒ
â”‚   â”œâ”€â”€ run_classifier_Yelp.py          # Yelp è¯„è®ºåˆ†ç±»ä»»åŠ¡å¾®è°ƒ:
â”‚   â”œâ”€â”€ pytorch_cache
â”‚   â””â”€â”€ results          # æ”»å‡» / è®­ç»ƒè¾“å‡ºç›®å½•
â”‚          â”œâ”€â”€ ag   
â”‚         â”‚   â”œâ”€â”€ bert_config.json
â”‚         â”‚   â”œâ”€â”€ eval_results.txt
â”‚         â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚         â”‚   â””â”€â”€ vocab.txt
â”‚          â””â”€â”€â€¦         
â”‚
â”œâ”€â”€ ESIM/                           #  ESIM æ¨¡å‹ç›®å½•ï¼ˆè‹¥ä½¿ç”¨ NLI ESIMï¼‰
â”‚   â”œâ”€â”€ esim/
â”‚   â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ .DS_Store
â”‚   â””â”€â”€ setup.py
â”‚
â””â”€â”€ tf_cache/                       # USEï¼ˆUniversal Sentence Encoderï¼‰ç¼“å­˜ç›®å½•
```

---

## ğŸ› ï¸ å¸¸è§é—®é¢˜è®°å½•

### 1. `pattern.en` å¯¼å…¥å¤±è´¥
å°† `from pattern.en import ...` ä¿®æ”¹ä¸º `from pattern.text.en import ...`ã€‚

### 2. NLTK èµ„æºç¼ºå¤±

```python
import nltk
nltk.download(['punkt', 'averaged_perceptron_tagger', 'universal_tagset', 'wordnet', 'omw-1.4'])
```

âš ï¸ è‹¥ `wordnet` ä¸‹è½½å¤±è´¥ï¼Œæ‰‹åŠ¨æ”¾ç½®è¯­æ–™åŒ…åˆ°ï¼š
`C:\Users\username\AppData\Roaming\nltk_data\corpora`

### 3. CUDA æŠ¥é”™

`AssertionError: Torch not compiled with CUDA enabled`  
è§£å†³æ–¹å¼ï¼šå®‰è£… GPU ç‰ˆæœ¬çš„ PyTorch æˆ–åœ¨æœ¬åœ°é‡æ–°é…ç½® CUDA + PyTorchã€‚

### 4. TensorFlow ç‰ˆæœ¬å†²çª

TensorFlow 1.x API åœ¨ 2.x ç¯å¢ƒä¸å…¼å®¹ï¼Œéœ€ä¿®æ”¹ä»£ç ï¼š

```python
import tensorflow as tf
tf.compat.v1.disable_eager_execution()
```

å¹¶å°†æ‰€æœ‰ TF1 API æ›¿æ¢ä¸º `tf.compat.v1.xxx`

---

## âœ… è‡´è°¢

æœ¬é¡¹ç›®åŸºäºå®˜æ–¹ TextFooler ä»£ç ä¿®æ”¹ä¼˜åŒ–ï¼Œé€‚é…æ–°ç‰ˆä¾èµ–ä¸ç¯å¢ƒã€‚æ¬¢è¿åœ¨åŸé¡¹ç›®åŸºç¡€ä¸Šè¿›è¡ŒäºŒæ¬¡å¼€å‘æˆ–å¤ç°å®éªŒç»“æœã€‚
 
 æ–¹æ³•ä¸ç»“æœå‚è€ƒä»¥è®ºæ–‡ï¼š Jin, Di, et al. "[Is BERT Really Robust? Natural Language Attack on Text Classification and Entailment](https://arxiv.org/pdf/1907.11932.pdf)." arXiv preprint arXiv:1907.11932 (2019)

